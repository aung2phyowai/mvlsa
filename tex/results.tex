\section{Experiments and Results}
\label{sec:exp}
Let us first enumerate the central questions which we wanted to answer through
our experiments: 
\begin{enumerate}[leftmargin=*]
  \itemsep-0.1em 
\item How do hyper parameters affect performance ?
%\item How much does the performance vary on different test sets and why ?
\item What is the contribution of the multiple sources of data to performance ?
\item How does the performance of MVLSA compare with other methods ?
\end{enumerate}

\noindent\textbf{Effect of Hyper parameters}: 
$f_j$: We modeled the preprocessing function $f_j$ as the composition
of two functions, i.e. $f_j = n_j \circ t_j$.
  $n_j$ represents nonlinear preprocessing that is usually
  employed with LSA. We experimented by setting $n_j$ to be
  Identity, logarithm of count plus one and the Fourth root of the
  count.
  %% \footnote{We also experimented with other powers of the counts (0.12, 0.5
  %% and 0.75) on a smaller dataset and found that the fourth root
  %% performed the best.}
  $t_j$ represents the truncation of columns and can be interpreted as
  a type of regularization of the raw counts themselves through which
  we prune away the noisy contexts. Decrease in $t_j$
  also reduces the influence of views that have a large number of
  context columns and emphasizes the sparser views. 
  Table~\ref{tab:n} and Table~\ref{tab:t} show the results.
\begin{table}[htbp]
  \begin{tabular}{=l| +c +c +c}
    Test Set                            & Log  & Count & Count$^{\frac{1}{4}}$ \\ \hline
    MEN                                 & 67.5 & 59.7  & \mb{70.7}                  \\
    RW                                  & 31.1 & 25.3  & \mb{37.8}                  \\
    SCWS                                & 64.2 & 58.2  & \mb{66.6}                  \\\remove{
    SIMLEX                              & 36.7 & 27.0  & \mb{38.0}                  \\
\rowstyle{\color{darkergray}}    WS     & 68.0 & 60.4  & \mb{70.5}                  \\
\rowstyle{\color{darkergray}}    MTURK  & 57.3 & 55.2  & \mb{60.8}                  \\
\rowstyle{\color{darkergray}}    WS-REL & 60.4 & 52.7  & \mb{62.9}                  \\
\rowstyle{\color{darkergray}}    WS-SEM & 75.0 & 67.2  & \mb{76.2}                  \\
\rowstyle{\color{darkergray}}    RG     & 69.1 & 55.3  & \mb{75.9}                  \\
\rowstyle{\color{darkergray}}    MC     & 70.5 & 67.6  & \mb{80.9}                  \\}
    T-SYN                               & 45.7 & 21.1  & \mb{53.6}                  \\
    T-SEM                               & 25.4 & 15.9  & \mb{38.7}                  \\\remove{
  \rowstyle{\color{darkergray}}  TOEFL  & 81.2 & 70.0  & \mb{81.2} }
  \end{tabular}
  \caption{Performance versus $n_j$, the non linear processing of
    Co-occurrence counts.$\, t =200K, \; m=500, \; v=16, \; k=300$.}
  \label{tab:n}
\end{table}

\begin{table}[htbp]
  \resizebox{0.5\textwidth}{!}{
  \begin{tabular}{=l | +c +c +c +c H +c H +c}
Test Set                            & 6.25K & 12.5K & 25K  & 50K  & 75K  & 100K & 150K & 200K \\ \hline
MEN                                 & 70.2  & \mi{71.2}  & \mi{71.5} & \mi{71.6} & \mi{71.4} & \mi{71.2} & \mi{71.0} & \mi{70.7} \\   
RW                                  & \mi{41.8}  & \mi{41.7}  & \mi{41.5} & \mi{40.9} & \mi{40.7} & 39.6 & 38.3 & 37.8 \\ 
SCWS                                & \mi{67.1}  & \mi{67.3}  & \mi{67.1} & \mi{67.0} & \mi{67.3} & \mi{66.9} & \mi{66.8} & \mi{66.6} \\ \remove{
SIMLEX                              & 42.7  & \mb{42.4}  & 41.9 & 41.3 & 40.5 & 39.5 & 38.4 & 38.0 \\ 
\rowstyle{\color{darkergray}}WS     & 68.1  & 70.8  & 71.6 & 71.2 & 71.3 & 70.2 & 70.8 & 70.5 \\ 
\rowstyle{\color{darkergray}}MTURK  & 62.5  & 59.7  & 59.2 & 58.6 & 58.3 & 60.3 & 61.0 & 60.8 \\ 
\rowstyle{\color{darkergray}}WS-REL & 60.8  & 65.1  & 65.7 & 64.8 & 65.2 & 63.7 & 63.7 & 62.9 \\ 
\rowstyle{\color{darkergray}}WS-SEM & 77.8  & 78.8  & 78.8 & 78.2 & 77.7 & 76.5 & 77.0 & 76.2 \\ 
\rowstyle{\color{darkergray}}RG     & 72.7  & 74.4  & 74.7 & 75.0 & 75.0 & 74.3 & 75.6 & 75.9 \\ 
\rowstyle{\color{darkergray}}MC     & 75.2  & 75.9  & 79.9 & 80.3 & 81.0 & 76.9 & 79.6 & 80.9 \\}
T-SYN                               & 59.2  & \mi{60.0}  & \mi{59.5} & 58.4 & 57.4 & 56.1 & 54.3 & 53.6 \\
T-SEM                               & 37.7  & \mi{38.6}  & \mi{39.4} & \mi{39.2} & \mi{39.4} & 38.4 & \mi{38.8} & \mi{38.7} \\\remove{
\rowstyle{\color{darkergray}}TOEFL  & 88.8  & 87.5  & 85.0 & 83.8 & 83.8 & 83.8 & 82.5 & 81.2}
      \end{tabular}
  }
  \caption{Performance versus the truncation threshold, $t$, of raw
    cooccurrence counts. We used $n_j=\textrm{Count}^{\frac{1}{4}}$
    and other settings were the same as Table~\ref{tab:n}.} 
  \label{tab:t}
\end{table}
$m$: The number of left singular vectors extracted after SVD of the preprocessed cooccurrence
  matrices can again be interpreted as a type of regularization, since
  the result of this truncation is that we find cooccurrence patterns 
  only between the top left singular vectors. We set $m_j = max(d_j,
  m)$ with $m=[100, 300, 500]$. See table~\ref{tab:n}.

\begin{table}[htbp]
  \begin{tabular}{=l | +c +c +c +c}
Test Set                            & 100  & 200  & 300  & 500  \\\hline
MEN                                 & 65.6 & 68.5 & \mi{70.1} & \mi{71.1} \\
RW                                  & 34.6 & \mi{36.0} & \mi{37.2} & \mi{37.1} \\
SCWS                                & 64.2 & \mi{65.4} & \mi{66.4} & \mi{66.5} \\\remove{
SIMLEX                              & 38.4 & 40.6 & \mb{41.1} & 40.3 \\
\rowstyle{\color{darkergray}}WS     & 60.4 & 67.1 & 69.4 & \mb{71.1} \\
\rowstyle{\color{darkergray}}MTURK  & 51.3 & 58.3 & 58.4 & \mb{58.9} \\
\rowstyle{\color{darkergray}}WS-REL & 49.0 & 58.2 & 61.6 & \mb{65.1} \\
\rowstyle{\color{darkergray}}WS-SEM & 73.6 & 76.8 & 76.8 & \mb{78.0} \\
\rowstyle{\color{darkergray}}RG     & 61.6 & 69.7 & 73.2 & \mb{74.6} \\
\rowstyle{\color{darkergray}}MC     & 65.6 & 74.1 & \mb{78.3} & 77.7 \\}
T-SYN                               & 50.5 & \mi{56.2} & \mi{56.4} & \mb{56.4} \\
T-SEM                               & 24.3 & 31.4 & 34.3 & \mb{40.6} \\\remove{
\rowstyle{\color{darkergray}} TOEFL & 80.0 & 81.2 & \mb{82.5} & 80.0}
  \end{tabular}                                        
  \caption{Performance versus $m$, the number of left     
singular vectors extracted from raw cooccurrence counts. We set
$n_j=\textrm{Count}^\frac{1}{4}, \; t=100K, \; v=25, \;
k=300$.} 
  \label{tab:m}
\end{table}

$k$: Table~\ref{tab:k} demonstrates the variation in performance
versus the dimensionsionality of the learnt vector representations of the
  words. Since the dimensions of the MVLSA representations are
  orthogonal to each other therefore creating lower dimensional
  representations is a trivial matrix slicing operation and does not
  require retraining.
  \begin{table}[htbp]
  \begin{tabular}{=l | +c H +c +c +c +c +c}
Test Set                            & 10   & 25   & 50   & 100  & 200       & 300       & 500       \\\hline
MEN                                 & 49.0 & 59.3 & 67.0 & \mb{69.7} & \mb{70.2} & \mi{70.1} & \mb{69.8}\\
RW                                  & 28.8 & 33.1 & 33.3 & 35.0 & 35.2      & \mb{37.2} & \mi{38.3} \\
SCWS                                & 57.8 & 62.8 & 64.4 & \mi{65.2} & \mi{66.1}      & \mb{66.4} & \mi{65.1}      \\\remove{
SIMLEX                              & 24.0 & 30.1 & 33.9 & 36.1 & 38.9      & 41.1      & \mb{42.0} \\
\rowstyle{\color{darkergray}}WS     & 46.8 & 57.5 & 63.4 & 69.5 & 69.5      & 69.4      & 66.0      \\
\rowstyle{\color{darkergray}}MTURK  & 54.6 & 65.9 & 67.7 & 61.6 & 60.5      & 58.4      & 57.4      \\
\rowstyle{\color{darkergray}}WS-REL & 38.4 & 49.5 & 55.8 & 63.1 & 62.4      & 61.6      & 56.3      \\
\rowstyle{\color{darkergray}}WS-SEM & 55.3 & 64.7 & 69.9 & 76.9 & 77.1      & 76.8      & 75.6      \\
\rowstyle{\color{darkergray}}RG     & 48.8 & 60.5 & 66.1 & 69.7 & 75.1      & 73.2      & 72.5      \\
\rowstyle{\color{darkergray}}MC     & 37.0 & 57.5 & 59.0 & 71.3 & 79.1      & 78.3      & 75.7      \\}
T-SYN                               & 9.0  & 28.4 & 41.2 & 52.2 & 55.4      & \mb{56.4} & 54.4      \\
T-SEM                               & 2.5  & 10.8 & 21.8 & 34.8 & \mb{35.8} & 34.3      & 33.8      \\\remove{
\rowstyle{\color{darkergray}} TOEFL & 57.5 & 73.8 & 72.5 & 76.2 & 81.2      & 82.5      & 85.0}
  \end{tabular}
  \caption{Performance versus $k$, the final dimensionality of the
    embeddings. We set $ m=300$ and other settings were same as Table~\ref{tab:m}.}
  
  \label{tab:k}
\end{table}

$v$: Recall that in Expression~\ref{eq:gcca3} we described a method to
  set $W_j$. We experimented with a different, more global, heuristic to
  set $[W_j]_{ii} = (K_{ww} \ge v)$. Essentially we removed all
  words that did not appear in $v$ views before doing
  GCCA. Table~\ref{tab:v} shows that changes in $v$ are largely
  inconsequential for performance. In abscence of clear evidence in favor of regularization we
  decided to regularize as little as possible and chose $v=16$. We were
  not able to set $v=0$ since our current implementation of GCCA
  procedure requires us to load the entire $\tilde{M}$ matrix in
  memory which is 45*500*500K*8 Bytes = 90GB.
  %% While this is certainly
  %% possible with current hardware a more memory efficient approach is
  %% desirable.
  This is a drawback of our current implementation and we
  are working on implementing a more scalable version of this
  algorithm so that we can run experiments with larger
  vocabularies. For our current experiments the largest vocabulary we
  used consisted of 361K words and had 100\% recall on all the test
  sets except for RW on which the recall was 92\%.
  %% Also note that though the
  %% size of $G$ decreases as we increase $v$ (and hence the recall of
  %% our embeddings) for these experiments the recall of the vocabulary
  %% over the test sets remained complete except for RW and T-SEM for
  %% which the recall was 1700 out of 2034 and 8714 out of 8869
  %% respectively.
  
  \begin{table}[htbp]
  \begin{tabular}{=l | +c +c H +c H +c H +c}
Test Set                            & 16   & 17   & 19   & 21   & 23   & 25   & 27   & 29   \\ \hline
MEN                                 & \mb{70.4} & \mb{70.4} & \mi{70.2} & \mi{70.2} & \mi{70.1} & \mi{70.1} & \mi{70.0} & \mi{70.0} \\
RW                                  & \mb{39.9} & \mi{38.8} & \mi{40.1} & \mi{39.7} & 38.3 & 37.2 & 35.3 & 33.5 \\
SCWS                                & \mb{67.0} & \mb{66.8} & \mb{66.8} & \mb{66.5} & \mb{66.3} & \mb{66.4} & \mb{66.1} & \mb{65.7} \\\remove{
SIMLEX                              & 40.7 & 41.0 & 41.1 & \mb{41.2} & 41.2 & 41.1 & 41.1 & 41.0 \\
\rowstyle{\color{darkergray}}WS     & 69.5 & 69.4 & 69.5 & 69.5 & 69.4 & 69.4 & 69.3 & 69.1 \\
\rowstyle{\color{darkergray}}MTURK  & 59.4 & 59.2 & 59.3 & 59.2 & 58.7 & 58.4 & 58.0 & 58.0 \\
\rowstyle{\color{darkergray}}WS-REL & 62.1 & 61.9 & 62.1 & 62.3 & 61.9 & 61.6 & 61.4 & 61.1 \\
\rowstyle{\color{darkergray}}WS-SEM & 76.8 & 76.8 & 76.9 & 77.0 & 76.7 & 76.8 & 76.7 & 76.8 \\
\rowstyle{\color{darkergray}}RG     & 73.0 & 72.8 & 72.7 & 72.8 & 73.6 & 73.2 & 73.4 & 73.7 \\
\rowstyle{\color{darkergray}}MC     & 75.0 & 76.0 & 76.4 & 76.5 & 78.2 & 78.3 & 78.6 & 78.6 \\}
T-SYN                               & \mb{56.0} & \mb{55.8} & \mb{56.0} & \mb{55.9} & \mb{56.3} & \mb{56.4} & \mb{56.3} & \mb{56.0} \\
T-SEM                               & \mb{34.6} & \mb{34.3} & \mb{34.1} & \mb{34.0} & \mb{34.5} & \mb{34.3} & \mb{34.4} & \mb{34.3} \\\remove{
\rowstyle{\color{darkergray}} TOEFL & 85.0 & 85.0 & 85.0 & 83.8 & 83.8 & 82.5 & 82.5 & 80.0}
    \end{tabular}
  \caption{Performance versus minimum view support threshold $v$, The other
      hyperparameters were $n_j=\textrm{Count}^{\frac{1}{4}}, \;
      m=300, \; t=100K$. Though a clear best setting did not emerge,
      we chose $v=25$ as the middle ground.}
  \label{tab:v}
\end{table}
  
$r_j$: The regularization parameter ensures that all the
  inverses exist at all points in our method. We found that the
  performance of our  procedure was invariant to $r$ over a large
  range from 1 to 1e-10. This was because even the 1000th singular
  value of  our data was much higher than 1 which is
  consistent with the observation that cooccurrence datasets in NLP
  tend to have gently sloping spectrum. For all the experiments in
  this paper we set $r=1e-5$.


\begin{table*}[ht]
  \label{tab:j}
   \setlength\tabcolsep{3pt}
  \begin{tabular}{=l| +c +c +c +c +c +c +c +c}
Test Set              & \specialcell{All\\Views} & !Framenet &
!Morphology & !Bitext & !Wikipedia & !Dependency &
\specialcell{!Morphology\\!Framenet} &
\specialcell{!Morphology\\!Framenet\\!Bitext} \\\hline
MEN                                 & \mb{70.1} & \mi{69.8} & \mi{70.1} & \mi{69.9} & 46.4 & 68.4 & \mi{69.5} & 68.4 \\
RW                                  & \mb{37.2} & \mi{36.4} & \mi{36.1} & 32.2 & 11.6 & 34.9 & 34.1 & 27.1 \\
SCWS                                & \mb{66.4} & \mi{65.8} & \mi{66.3} & 64.2 & 54.5 & \mi{65.5} & \mi{65.2} & 60.8 \\\remove{
SIMLEX                              & 41.1 & 40.1 & 41.1 & 37.8 & 32.4 & \mb{44.1} & 38.9 & 34.4 \\
\rowstyle{\color{darkergray}}WS     & 69.4 & 69.1 & 69.2 & 67.6 & 43.1 & 70.5 & 69.3 & 66.6 \\
\rowstyle{\color{darkergray}}MTURK  & 58.4 & 58.3 & 58.6 & 55.9 & 52.7 & 59.8 & 57.9 & 55.3 \\
\rowstyle{\color{darkergray}}WS-REL & 61.6 & 61.5 & 61.4 & 59.4 & 38.2 & 63.5 & 62.5 & 58.8 \\
\rowstyle{\color{darkergray}}WS-SEM & 76.8 & 76.3 & 76.7 & 75.9 & 48.1 & 75.7 & 75.8 & 73.1 \\
\rowstyle{\color{darkergray}}RG     & 73.2 & 72.0 & 73.2 & 73.7 & 45.0 & 70.8 & 71.9 & 74.0 \\
\rowstyle{\color{darkergray}}MC     & 78.3 & 75.7 & 78.2 & 78.2 & 46.5 & 77.5 & 76.0 & 80.2 \\}
T-SYN                               & \mb{56.4} & \mi{56.3} & \mi{56.2} & 51.2 & 37.6 & 50.5 & 54.4 & 46.0 \\
T-SEM                               & 34.3 & 34.3 & 34.3 & \mb{36.2} & 4.1  & 35.3 & 34.5 & 30.6 \\\remove{
\rowstyle{\color{darkergray}}TOEFL  & 82.5 & 82.5 & 82.5 & 71.2 & 45.0 & 85.0 & 82.5 & 65.0   }
  \end{tabular}
  \parbox{\textwidth}{\caption{Performance versus views removed from
      the multiview GCCA procedure. !Framenet means that the view
      containing counts derived from Frame semantic dataset was
      removed. Other columns are named similarly. The other
      hyperparameters were $n_j=\textrm{Count}^{\frac{1}{4}}, \;
      m=300, \; t=100K, \; v=25, \; k=300$. }}
\end{table*}
  
\noindent\textbf{Contribution of different sources of data}:
 Table~\ref{tab:j} shows an ablative analysis of performance where we
 remove individual views or some combination of them and measure the
 performance.  It is clear by comparing the last column to the second
 column that adding in more views 
 improves performance. Also we can see that the Dependency based views and the Bitext
 based views give a larger boost than the morphology and FrameNet
 based views, probably because the latter are so sparse.

\noindent\textbf{Comparison to other word representation creation methods:}
There are a large number of methods of creating representations both
multilingual and monolingual. We directly compare our method to the
monolingual systems Glove and Word2Vec as their performance is widely
considered to be the state of the art.
%% We acknowledge that there 
%% exist other methods such as the 3CosMul method proposed in
%% \cite{levy2014dependency} or the Multimodal neural embedding methods
%% presented recently in \cite{felix2014learning,weston2014hash} 
We trained the two systems on the English portion of the
\textit{Polyglot} Wikipedia dataset.\footnote{More specifically
we explicitly provided the vocabulary file to Glove and Word2Vec and set the
truncation threshold for word2Vec to 10. Also Glove was trained for 25
iterations and both methods used window of 15 previous words.}

To make a fair comparison we also provide 
results where we used only the views derived from the \textit{Polyglot}
wikipedia corpus. See column ``MVLSA (Monolingual)'' in Table~\ref{tab:c}. 
We also combined the embeddings created by different methods again
using GCCA and results are presented in columns titled ``Combined''. The Combined
models outperform all the three constituent methods which shows that
the three methods were learning different patterns from the
data and that pooling these experts by using GCCA was useful. Using GCCA itself for system combination provides closure
for the MVLSA algorithm since more and more algorithms can now be combined by using the same method.

%% for c in glove glove_0  word2vec; do \
%%            echo $$c ; $(MAKE) -s ts_extrinsic_"$$c"_mytrain_mycode; done
%%         echo "monolingMVLSA"; make -s ts_fullgcca_extrinsic_test_v5_embedding_mc_CountPow025-truncco\
%% l12500_500~E@mi@bi@ag@fn@mo,300_1e-5_170000.300.1.1 ; \
%%         echo "MVLSA"; make -s ts_fullgcca_extrinsic_test_v5_embedding_mc_CountPow025-trunccol12500_5\
%% 00~E@mi,300_1e-5_16.300.1.1 ;\
%%         echo "3combo"; make -s ts_combined_embedding_0; \
%%         echo "2combo"; make -s ts_combined_embedding_1 \

\begin{table*}[ht]
    \begin{adjustwidth}{-2cm}{}
      \rowcolors{1}{}{lightgray}
  \setlength\tabcolsep{2pt}
  \begin{tabular}{=l| +c +c +c | +c +c +c +c H H | +c +c H +c +c}
    Test Set &
    \specialcell{LC\\(0.05,0.7)} &
    Glove  &
    Word2Vec &
    \specialcell{MVLSA\\Monolingual} &
    \specialcell{MVLSA\\All Views}&
    \specialcell{$\rho$ \\Glove}&
    \specialcell{$\rho$ \\Word2Vec}&
    Increment  &
    Gap &
    \specialcell{Glove, Word2Vec\\Combined} &
    \specialcell{All\\Combined} &
    Increment &
    \specialcell{$\rho$ \\Glove}&
    \specialcell{$\rho$ \\Word2Vec}\\\hline
    
MEN                                & 2.3  & 70.4       & \myu{73.9} & 71.4 & 71.2 & 72 & 90 & -0.2      & -2.7  & 76.0 & \myu{75.8} & -0.2      & 84 & 92 \\
RW                                 & 2.8  & 28.1       & 32.9       & 29.0 & 41.7 & 70 & 71 & \mb{12.7} & 8.8   & 37.2 & \myu{40.5} & \mb{3.3}  & 77 & 73 \\
SCWS                               & 2.8  & 54.1       & \myu{65.6} & 61.8 & 67.3 & 72 & 86 & \mb{5.5}  & 1.7   & 60.7 & \myu{66.4} & \mb{5.7}  & 78 & 89 \\
SIMLEX                             & 4    & 33.7       & 36.7       & 34.5 & 42.4 & 61 & 77 & \mb{7.9}  & 5.7   & 41.1 & \myu{43.9} & 2.8       & 77 & 84 \\
WS                                 & 6.7  & 58.6       & \myu{70.8} & 68.0 & 70.8 & 69 & 87 & 2.8       & 0     & 67.4 & \myu{70.1} & 2.7       & 78 & 90 \\
MTURK                              & 7.5  & \myu{61.7} & \myu{65.1} & 59.1 & 59.7 & 70 & 77 & 0.6       & -5.4  & 59.8 & \myu{62.9} & 3.1       & 79 & 83 \\
WS-REL                             & 8    & 53.4       & \myu{63.6} & 60.1 & 65.1 & 58 & 80 & 5         & 1.5   & 59.6 & \myu{63.5} & 3.9       & 69 & 84 \\
WS-SEM                             & 8.9  & \myu{69.0} & \myu{78.4} & 76.8 & 78.8 & 72 & 89 & 2         & 0.4   & 76.1 & \myu{79.2} & 3.1       & 80 & 92 \\
\rowstyle{\color{darkergray}}RG    & 16   & \myu{73.8} & \myu{78.2} & 71.2 & 74.4 & 76 & 89 & 3.2       & -3.8  & 80.4 & \myu{80.8} & 0.4       & 89 & 89 \\
\rowstyle{\color{darkergray}}MC    & 23.9 & \myu{70.5} & \myu{78.5} & 76.6 & 75.9 & 77 & 93 & -0.7      & -2.6  & 82.7 & \myu{77.7} & -5        & 88 & 91 \\
T-SYN                              & 0.68 & 61.8       & 59.8       & 42.7 & 60.0 &    &    & \mb{17.3} & -1.8  & 51.0 & \myu{64.3} & \mb{13.3} &    &    \\
T-SEM                              & 0.74 & \myu{80.9} & 73.7       & 36.2 & 38.6 &    &    & \mb{2.4}  & -42.3 & 73.5 & 77.2       & \mb{3.7}  &    &    \\
\rowstyle{\color{darkergray}}TOEFL & 6.30 & \myu{83.8} & 81.2       & 78.8 & 87.5 &    &    & \mb{8.7}  & 3.7   & 86.2 & \myu{88.8} & 2.6       &    & 
  \end{tabular}
  \caption{Comparison of Word2Vec, Glove and Multiview LSA. Change in
    accuracy from the use of multiple views that is higher than LC is
    in bold and the top scoring entries from the Glove, Word2Vec and Combined(All)
  columns are underlined when the difference in their scores from the
  top one is less than LC.}
  \label{tab:c}
  \end{adjustwidth}
\end{table*}
