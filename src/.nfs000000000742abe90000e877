% view is the data
% label are the labels of the data
% knnK are the K 
% distance is either euclidean, or cosine but NEVER correlation
% cosine means no mean substract
function [time_taken, acc]=knn_performance(view, label, knnK, distance, ...
                                           crossval_fold)

% check that knn_performance([1 2 ; 3 4; 5 6], [1 2 2]', 1, 10) is reasonable
knnK=knnK+1; %Since the knn query function also returns itself in the result.

% performance_func=@(idx, label, len) ...
%     sum(arrayfun(@(i) sum(label(idx(i,:))==label(i))-1, 1:len))/ ...
%     len;
% tree=kdtree_build(view);
% idx = cell2mat(arrayfun(@(i) kdtree_k_nearest_neighbors(tree, view(i,:), ...
%                                                knnK)', (1:len)', ...
%                'UniformOutput', 0));
% [distance, idx]=knn(view', view', knnK)
% acc=performance(idx, label, len);
tic; 
tmp=view*view';
perf=0;
indices=crossvalind('Kfold', label, crossval_fold);
for i=1:10
    test=(indices==i);
    train=~test;
    class=knnclassify(view(test,:), view(train,:), label(train), ...
                      knnK, distance, 'nearest');
    perf=perf+sum(class==label(test));
end
acc=perf/length(label);
time_taken=toc;