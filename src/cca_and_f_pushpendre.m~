%% Input Variables Section
% 1. filename - The name of filename which contains the embeddings
% of synonyms. Currently it is assumed that 1 and 2 are synonyms
% and 3-4 are synonyms and so on.
% 2. columns - the offset of columns from left. (This many columns
% would not be read and the columns after it would be read)
% 3. dimension_after_cca
%% Basic Lambdas
util_funcs;
%% Prepare input
wordsfile=[filename '_words'];
arr=dlmread(filename, '', 1, columns);
words=textread(wordsfile, '%s');
view1 = arr(1:2:size(arr,1),:);
view2 = arr(2:2:size(arr,1),:);
assert(all(size(view1)==size(view2)));
%% Do synonymous partitions (With Raman's regularized cca)
if 1
    canoncorr_reg = @(v1, v2) cca_raman(v1', v2', 1e-8, 1e-8, ...
                                        min(size(v1,2), size(v2,2)));
    [Wx,Wy,r] = canoncorr_reg(view1, view2);
    U = (view1-repmat(mean(view1),size(view1, 1),1))*Wx;
    V = (view2-repmat(mean(view2),size(view2, 1),1))*Wy;
    tmp_raman=corr(U,V);
    if(usejava('desktop'))
        figure; show_orthogonality(U, V);
        figure; show_correlation(U);
        figure; show_correlation(V);
    end
    f_measure_orig_raman = f_measure(view1, view2); 
    U=U(:, 1:dimension_after_cca);
    V=V(:, 1:dimension_after_cca);
    f_measure_cca_raman = f_measure(U, V);
    saveas(make_word_cloud(U, V, words), 'cca_word_cloud_proper_embedding_proper_partition.png');
    disp(f_measure_cca_raman);
    disp(f_measure_orig_raman);
end
%% KNN classifier
% Note that ideally you will do NCA, but here we just want to find
% out the performance of CCA on this objective. as baseline.

% First we need to figure out performance of original embeddings on
% this KNN objective. For that I need to tune the k by using leave
% one out on the train data.
classes=size(view1, 1);
for n=1:1
    [idx,D]=knnsearch(view1, view2, n);
    disp(['Knn leave one out, K =' sprintf('%d', n) ' Before CCA']);
    disp(leave1out_performance(idx, classes));
    
    [idx,D]=knnsearch(U, V, n);
    disp(['Knn leave one out, K =' sprintf('%d', n) ' After CCA']);
    disp(leave1out_performance(idx, classes));
end
%% Create synonymous partition of embeddings (using matlab canoncorr)
if 0
    % The problem with canoncorr and why we dont use it is that it
    % doesnot allow regularization and no svds.
    [A,B,~,U,V,stats]=canoncorr(view1, view2);
    tmp1=(corr(U,V));
    f_measure_orig = f_measure(view1, view2); 
    U=U(:, 1:dimension_after_cca);
    V=V(:, 1:dimension_after_cca);
    f_measure_cca = f_measure(U, V);
    disp([f_measure_cca  f_measure_orig]);
end
%% Create random embeddings and their partitions
if 0
    view1_n = randn(size(view1));
    view2_n = randn(size(view2));
    [A,B,~,U,V,stats]=canoncorr(view1_n, view2_n);
    if(usejava('desktop'))
        figure; show_orthogonality(U, V);
        figure; show_correlation(U);
        figure; show_correlation(V);
    end
    f_measure_orig = f_measure(view1_n, view2_n); 
    U=U(:, 1:dimension_after_cca);
    V=V(:, 1:dimension_after_cca);
    saveas(make_word_cloud(U, V, words), 'cca_word_cloud_random_embedding.png');
    f_measure_cca = f_measure(U, V);
    disp([f_measure_cca  f_measure_orig]);    
end
%% Do random partitions of mikolov embeddings
if 0
    perm = randperm(size(arr,1));
    view1 = arr(perm(1:500),:);
    view2 = arr(perm(501:1000),:);
    [A,B,~,U,V,stats]=canoncorr(view1, view2);
    f_measure_orig_randpart = f_measure(view1, view2); 
    U=U(:, 1:dimension_after_cca);
    V=V(:, 1:dimension_after_cca);
    make_word_cloud(U, V, words);
    f_measure_cca_randpart = f_measure(U, V);
    disp([f_measure_cca_randpart  f_measure_orig_randpart]);
end
%% Results upto here
%     4.7937    0.7510 (partition by synonyms, use canoncorr)
%     4.7937    0.7510 (partition by synonyms, use ramancorr)
%     2.9818    0.5024 (random vectors)
%     3.1024    0.4925 (random partition of mikolov embeddings)
% This begs the questions how to normalize the original embeddings ? 
% Are the original embeddings normal or not ?
%    3.0125    0.5077 (partition by 80 of the dimensions, (it shouldn't matter cause its LSH right??)
%    3.0125    0.5077 (raman_cca)
%    3.0803    0.5117 (randome permutation)
% Also my metric is not invariant of how many dimensions I keep at the end

